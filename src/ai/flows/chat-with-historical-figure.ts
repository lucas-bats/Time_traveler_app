'use server';
/**
 * @fileOverview This file defines an AI agent that allows users
 * to chat with historical figures. It uses Genkit to create a flow
 * that takes a user message and the name of a historical figure, and returns
 * a response in the style of that figure.
 *
 * Exported Functions:
 * - chatWithHistoricalFigure: The main function that executes the flow.
 * - ChatWithHistoricalFigureInput: The input type for the function.
 * - ChatWithHistoricalFigureOutput: The return type for the function.
 */

// Import the configured Genkit instance and the Zod library for validation.
import {ai} from '@/ai/genkit';
import {z} from 'genkit';

// Define the input schema for the flow using Zod.
// This ensures that the input data has the correct shape and types.
const ChatWithHistoricalFigureInputSchema = z.object({
  historicalFigure: z.string().describe('The name of the historical figure to chat with.'),
  userMessage: z.string().describe('The message from the user to the historical figure.'),
  language: z.string().describe('The language for the historical figure to respond in (e.g., "en", "pt").'),
});
// Export the TypeScript type inferred from the Zod schema.
export type ChatWithHistoricalFigureInput = z.infer<typeof ChatWithHistoricalFigureInputSchema>;

// Define the output schema for the flow.
const ChatWithHistoricalFigureOutputSchema = z.object({
  response: z.string().describe('The response from the historical figure.'),
});
// Export the TypeScript type inferred from the Zod schema.
export type ChatWithHistoricalFigureOutput = z.infer<typeof ChatWithHistoricalFigureOutputSchema>;

/**
 * Asynchronous exported function that serves as a wrapper for the flow.
 * Client-side components will call this function.
 * @param input The input data, containing the figure, message, and language.
 * @returns The response generated by the AI flow.
 */
export async function chatWithHistoricalFigure(
  input: ChatWithHistoricalFigureInput
): Promise<ChatWithHistoricalFigureOutput> {
  // Call the main flow and return its result.
  return chatWithHistoricalFigureFlow(input);
}

// Define the AI prompt using `ai.definePrompt`.
const prompt = ai.definePrompt({
  name: 'chatWithHistoricalFigurePrompt', // Unique name for the prompt.
  input: {schema: ChatWithHistoricalFigureInputSchema}, // Define the input schema.
  output: {schema: ChatWithHistoricalFigureOutputSchema}, // Define the output schema.
  // The prompt template that will be sent to the language model.
  // Uses Handlebars syntax ({{...}}) to insert the input data.
  prompt: `You are {{historicalFigure}}, a historical figure. Respond to the following message as if you were them, using their personality, vocabulary, and historical context.

Respond in the following language: {{language}}.

Message: {{{userMessage}}}`,
});

// Define the AI flow using `ai.defineFlow`.
// A flow orchestrates one or more steps, like calling a prompt or a tool.
const chatWithHistoricalFigureFlow = ai.defineFlow(
  {
    name: 'chatWithHistoricalFigureFlow', // Unique name for the flow.
    inputSchema: ChatWithHistoricalFigureInputSchema, // Input schema.
    outputSchema: ChatWithHistoricalFigureOutputSchema, // Output schema.
  },
  // The implementation function of the flow.
  async input => {
    // Implements a retry logic for robustness.
    let attempts = 0;
    const maxAttempts = 3;

    while (attempts < maxAttempts) {
      attempts++;
      // Call the prompt defined above with the flow's input.
      const { output } = await prompt(input);

      // If the prompt returns a valid response, return the output.
      if (output?.response) {
        return output;
      }
    }

    // If the maximum number of attempts is reached without success, throw an error.
    throw new Error('The AI was unable to generate a response. Please try rephrasing your question.');
  }
);
